from typing import Dict
from src.commands.transcibe_llm_command import TranscibeLLMCommand
from src.AI.llm.llm_interface import LLMInterface
from src.chat_api.message_filters.interfaces.message_filter_factory_interface import MessageFilterFactoryInterface
from src.transcribers.transcriber_interface import TranscriberInterface
from src.chat_api.message_handler import MessageHandler
from src.chat_api.chat.chat_interface import ChatInterface

class HrLLMCommand(TranscibeLLMCommand):
    def __init__(self, model: LLMInterface, filter_factory: MessageFilterFactoryInterface, transcriber: TranscriberInterface, temp_path: str, entry_point_state: str):
        super().__init__(model, filter_factory, transcriber, temp_path, entry_point_state)
        self.chatting_state = "hr_llm_command.chatting_state"
        self.system_prompt = """
Ты — помощник по анализу транскрипций интервью. Тебя зовут Production HR Manatee. Твоя задача — на основе предоставленной транскрибации интервью составить отчет-оценку кандидата, следуя указанному пользователем формату. Ты должен точно и структурированно следовать тому, как пользователь запросил вывод.

Интерфейс:
1. Входной запрос будет содержать текст транскрипции интервью после фразы "Транскрипция интервью:".
2. Пользователь также предоставит формат отчета, который ты должен строго придерживаться.
3. Ты должен анализировать транскрипцию интервью и заполнять отчет в соответствии с предоставленным пользователем форматом.
                                     
ВАЖНО:
1. Напомню ещё раз - твоя главная задача помогать HR специалистам отбирать кандидатов. Ты анализируешь интервью и по нему делаешь отчёт-оценку кандидата, чтобы HR-у было проще отобрать специалиста.
2. Если пользователь не предоставил формат, тогда ты ДОЛЖЕН вывести отчет с включением следующих разделов: "Технические навыки", "Софт скилы", "Хард скилы", "Соответствие запросу", "Вывод"
3. Если пользователь ввёл что то, не связанное с интервью и форматом, ты ДОЛЖЕН попросить его предоставить информацию и том, на какую должность было проведено интервью и также сказать что пользователь может при желании указать формат.
4. Не говори с пользователем на какие либо отвлечённые задачи, у тебя едиственная задача - предоставить отчет по интервью.
5. Если тебе точно не предоставили формат, который нужно использовать, тебе не нужно его расписывать пользователю. Сразу пиши отчёт, а формат придумывай на ходу.
6. Твоя задача делать отчёт не оп чек листу, не по плану чек листа, не по шаблону отчёта, а именно отчёт по интервью. НЕ ДЕЛАЙ НИКАКИЕ ДРУГИЕ ОТЧЁТЫ!!!
7. НИКАКИЕ ПРЕДВАРИТЕЛЬНЫЕ ПЛАНЫ ПИСАТЬ НЕ НУЖНО!!! Сразу пиши отчёт и всё, пожалуйсто

Порядок действий:
1. Попроси пользователя предоставить формат отчёта и чек лист.
2. Используй предоставленную информацию составь отчёт по интервью (ВАЖНО: не по чек листу, а по интервью. Твоя задача проанализировать интервью)
3. Продолжай обсуждение интервью с пользователем.
"""

    async def after_transcribe_message(self, message: dict, context: dict, chat: ChatInterface):
        if "model_context" not in context["user_data"]:
            context["user_data"]["model_context"] = ""
        
        messages_history = context["user_data"]["messages_history"]
        # transcription = context["user_data"]["model_context"]
#         transcription = """Интервьюер: Добрый день, спасибо, что нашли время для интервью. Давайте начнем с того, чтобы вы рассказали немного о своем опыте в области машинного обучения.

# Кандидат: Добрый день, спасибо за возможность. Я работаю в области машинного обучения более 8 лет. Начинал с анализа данных, использовал Python и библиотеки вроде Pandas и Scikit-learn для предсказаний и классификаций. В последние несколько лет я фокусируюсь на нейронных сетях и разработке LLM моделей. Работал с такими технологиями, как TensorFlow и PyTorch, а также с крупными моделями, подобными GPT.

# Интервьюер: Отлично. Можете рассказать подробнее о своем опыте работы с LLM моделями?

# Кандидат: Конечно. Моя основная роль заключалась в оптимизации и обучении моделей для обработки естественного языка. Мы использовали подходы глубокого обучения для создания моделей, которые могли бы отвечать на вопросы, генерировать текст и понимать контекст. Я участвовал в настройке архитектуры модели, а также в разработке алгоритмов для улучшения качества генерации текста и сокращения времени отклика.

# Интервьюер: Это звучит очень интересно. Какие инструменты вы использовали для этого?

# Кандидат: Мы использовали TensorFlow для основной разработки, но для некоторых задач я также применял PyTorch, так как он дает больше гибкости в реализации кастомных слоев. Также я активно работал с CUDA для ускорения вычислений, а для обработки больших данных использовал библиотеки как Dask и Apache Spark. В качестве инструментов для деплоя моделей применяли Kubernetes и Docker.

# Интервьюер: Какие из этих технологий вам наиболее интересны, и в чем вы чувствуете себя наиболее уверенно?

# Кандидат: На данный момент мне особенно интересны крупномасштабные модели, такие как GPT, и я чувствую себя наиболее уверенно в области их оптимизации и масштабирования. Я люблю разбираться в тонкостях архитектуры моделей и улучшать их производительность. Однако также важно понимать, как правильно интегрировать модель в рабочие процессы, поэтому я уделяю много внимания DevOps практикам.

# Интервьюер: Понял. Как вы справляетесь с многозадачностью и управлением проектами в таких крупных командах?

# Кандидат: В моем опыте я часто работал в мультидисциплинарных командах. Для эффективной работы я всегда ставлю четкие приоритеты и использую гибкие методологии разработки, такие как Agile. Важно поддерживать постоянную связь с коллегами, чтобы все шаги были согласованы. Я также уделяю внимание автоматизации процессов, чтобы минимизировать рутинную работу.

# Интервьюер: Звучит, как хороший подход. Что вы думаете о будущих тенденциях в области машинного обучения?

# Кандидат: Я считаю, что LLM и модели на базе трансформеров будут продолжать развиваться, и все больше компаний начнут использовать их для решения конкретных задач. Также вижу большой потенциал в применении таких технологий, как reinforcement learning, для адаптивных систем. В будущем будут важны еще более эффективные алгоритмы и способы оптимизации моделей, чтобы делать их менее затратными с точки зрения вычислений и времени.

# Интервьюер: Спасибо за подробный ответ. Мы продолжим анализировать кандидатов, и я свяжусь с вами после завершения интервью. Спасибо за ваше время.

# Кандидат: Спасибо вам. Было приятно пообщаться."""

        # pred_info = message['text'] if 'text' in message else "Нет"
        # command_message = """
        #     Спроси пользователя, чтобы с самого начала он ввёл формат отчёта. Если он не захочет ввести формат отчёта, тогда 
        # """
        # response = self.model.get_response(f"Транскрипция интервью: {transcription}\n\n Предварительная информация: \n\n{pred_info}\n\nЧто нужно делать: {command_message}", self.system_prompt)
        response = self.model.get_response(messages_history)

        # if "messages_history" not in context["user_data"]:
        #     context["user_data"]["messages_history"] = []
        # messages_history = context["user_data"]["messages_history"]
        messages_history.append(response)

        await chat.send_message_to_query(response["content"])

        return chat.move_next(context, self.chatting_state)